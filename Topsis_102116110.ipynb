{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPDQb8+Zppq1P+iIEkomV71"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5T1FrOAy9ptl","executionInfo":{"status":"ok","timestamp":1706465632642,"user_tz":-330,"elapsed":439,"user":{"displayName":"Ehsaas Dhand","userId":"16708076187157975104"}},"outputId":"41553bcc-5024-4a6a-ce94-9e9df8715a3c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Usage: python topsis.py <InputDataFile> <Weights> <Impacts> <ResultFileName>\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import sys\n","\n","data='/content/102116110-data.csv'\n","def read_data_for_topsis(data):\n","    try:\n","        dataset = pd.read_csv(data)\n","        return dataset\n","    except FileNotFoundError:\n","        print(\"Error: File not Found\")\n","        return None\n","\n","\n","def weights_and_impacts_for_topsis(weights, impacts):\n","    try:\n","        weights_array_for_topsis = np.fromiter( map(float, weights.split(',')), dtype=float)\n","        used_symbols = impacts.split(',')\n","        symbol_to_number_for_topsis= {'+': 1, '-': -1}\n","        num = [symbol_to_number_for_topsis[symbol.strip()] for symbol in used_symbols]\n","        impacts_array_for_topsis = np.array(num)\n","        return weights_array_for_topsis, impacts_array_for_topsis\n","    except ValueError as ed:\n","        print(f\"Error parsing weights and impacts: {ed}\")\n","        return None, None\n","\n","\n","def check_columns_for_topsis(dataset):\n","    try:\n","        return len(dataset.iloc[0]) >= 3\n","    except Exception as ed:\n","        print(f\"Error checking for  columns: {ed}\")\n","        return False\n","\n","\n","def normalize_data_for_topsis(dataset):\n","    num_values = dataset.iloc[:, 1:].values.tolist()\n","    num_values = np.array(num_values)\n","    normalized_matrix_ = num_values / \\\n","np.sqrt((num_values ** 2).sum(axis=0))\n","    return normalized_matrix_\n","\n","\n","def do_topsis(normalized_data_for_topsis, weights, impacts):\n","    weighted_matrix_ = normalized_data_for_topsis * weights * impacts\n","\n","    positive_ideal_solution = np.abs(np.array([weighted_matrix_[:, i].max() if weights[i] > 0 else weighted_matrix_[:, i].min() for i in range(len(weights))]))\n","    negative_ideal_solution = np.abs(np.array([weighted_matrix_[:, i].min(\n"," ) if weights[i] > 0 else weighted_matrix_[:, i].max() for i in range(len(weights))]))\n","\n","    weighted_matrix_ = np.abs(weighted_matrix_)\n","\n","    euclidean_dist_positive_ideal = np.sqrt(((weighted_matrix_ - positive_ideal_solution) ** 2).sum(axis=1))\n","    euclidean_dist_negative_ideal = np.sqrt(((weighted_matrix_ - negative_ideal_solution) ** 2).sum(axis=1))\n","\n","    closeness_coeff = euclidean_dist_negative_ideal / \\\n","        (euclidean_dist_positive_ideal + euclidean_dist_negative_ideal)\n","    return closeness_coeff\n","\n","\n","def check_num_values(dataset):\n","    try:\n","        numeric_columns = dataset.iloc[:, 1:].apply( pd.to_numeric, errors='coerce').notnull().all(axis=0)\n","        return numeric_columns.all()\n","    except Exception as ed:\n","        print(f\"Error checking numeric values: {ed}\")\n","        return False\n","\n","def consistency_for_topsis(weights, impacts, dataset):\n","    try:\n","        return len(weights) == len(impacts) == len(dataset.columns) - 1\n","    except Exception as ed:\n","        print(f\"Error checking consistency: {ed}\")\n","        return False\n","\n","\n","def impacts(impacts):\n","    try:\n","        return all(impact in [-1, 1] for impact in impacts)\n","    except Exception as ed:\n","        print(f\"Error checking impacts: {ed}\")\n","        return False\n","\n","\n","def write_result_for_topsis(result_file_, results):\n","    df = pd.DataFrame({'Values': results})\n","    df['Rank'] = (len(df) + 1) - df['Values'].rank()\n","    df.to_csv(result_file_, index=False)\n","    print(f\"Results have been saved to {result_file_}\")\n","\n","\n","def topsis(data, weights, impacts, result_file_):\n","    dataset = read_data_for_topsis(dataset)\n","    if dataset is None:\n","        return\n","\n","    weights_array_for_topsis, impacts_array_for_topsis= weights_and_impacts_for_topsis(weights,impacts)\n","\n","    if not check_columns_for_topsis(dataset) or not check_num_values(dataset) or not consistency_for_topsis(weights_array_for_topsis, impacts_array_for_topsis, data) or not impacts(impacts_array_for_topsis):\n","        print(\"Input conditions are not Exiting.\")\n","        return\n","\n","    normalized_data = normalize_data_for_topsis(dataset)\n","    results = do_topsis(normalized_data, weights_array_for_topsis, impacts_array_for_topsis)\n","    write_result_for_topsis(result_file_, results)\n","\n","\n","if __name__ == \"__main__\":\n","    if len(sys.argv) != 5:\n","        print(\n","            \"Usage: python topsis.py <InputDataFile> <Weights> <Impacts> <ResultFileName>\")\n","    else:\n","        input_file = sys.argv[1]\n","        weights = sys.argv[2]\n","        impacts = sys.argv[3]\n","        result_file_ = sys.argv[4]\n","\n","        topsis(data, weights, impacts, result_file_)\n","\n"]},{"cell_type":"code","source":[],"metadata":{"id":"6SzlikJMRxzm"},"execution_count":null,"outputs":[]}]}